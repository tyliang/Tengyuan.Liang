<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.34" />
  <meta name="author" content="Tengyuan Liang">

  
  
  
  
    
      
    
  
  <meta name="description" content="Consider the problem: given data pair $(\mathbf{x}, \mathbf{y})$ drawn from a population with $f_\star(x) = E[ \mathbf{y} | \mathbf{x} = x]$, specify a neural network and run gradient flow on the weights over time until any stationarity. How does *$f_t$*, the function computed by the neural network at time t, relate to *$f_\star$*, in terms of approximation and representation? What are the provable benefits of the adaptive representation by neural networks compared to the pre-specified fixed basis representation in the classical nonparametric literature? We answer the above questions via a dynamic reproducing kernel Hilbert space (RKHS) view indexed by the training process of neural networks. We show that when reaching any local stationarity, gradient flow learns an adaptive RKHS representation, and performs the global least squares projection onto the adaptive RKHS, simultaneously. In addition, we prove that as the RKHS is data-adaptive and task-specific, the residual for *$f_\star$* lies in a subspace that is smaller than the orthogonal complement of the RKHS, formalizing the representation and approximation benefits of neural networks.">

  
  <link rel="alternate" hreflang="en-us" href="http://tyliang.github.io/Tengyuan.Liang/publication/14-kernel-nn/">

  


  

  
  
  <meta name="theme-color" content="#EF525B">
  
  
  
  
    
  
  
    
    
      
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
      
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">
  
  
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  
  <link rel="stylesheet" href="/Tengyuan.Liang/styles.css">
  

  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-114381776-2', 'auto');
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  

  
  <link rel="alternate" href="http://tyliang.github.io/Tengyuan.Liang/index.xml" type="application/rss+xml" title="Tengyuan Liang">
  <link rel="feed" href="http://tyliang.github.io/Tengyuan.Liang/index.xml" type="application/rss+xml" title="Tengyuan Liang">
  

  <link rel="manifest" href="/Tengyuan.Liang/site.webmanifest">
  <link rel="icon" type="image/png" href="/Tengyuan.Liang/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/Tengyuan.Liang/img/icon-192.png">

  <link rel="canonical" href="http://tyliang.github.io/Tengyuan.Liang/publication/14-kernel-nn/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Tengyuan Liang">
  <meta property="og:url" content="http://tyliang.github.io/Tengyuan.Liang/publication/14-kernel-nn/">
  <meta property="og:title" content="Training Neural Networks as Learning Data-adaptive Kernels: Provable Representation and Approximation Benefits | Tengyuan Liang">
  <meta property="og:description" content="Consider the problem: given data pair $(\mathbf{x}, \mathbf{y})$ drawn from a population with $f_\star(x) = E[ \mathbf{y} | \mathbf{x} = x]$, specify a neural network and run gradient flow on the weights over time until any stationarity. How does *$f_t$*, the function computed by the neural network at time t, relate to *$f_\star$*, in terms of approximation and representation? What are the provable benefits of the adaptive representation by neural networks compared to the pre-specified fixed basis representation in the classical nonparametric literature? We answer the above questions via a dynamic reproducing kernel Hilbert space (RKHS) view indexed by the training process of neural networks. We show that when reaching any local stationarity, gradient flow learns an adaptive RKHS representation, and performs the global least squares projection onto the adaptive RKHS, simultaneously. In addition, we prove that as the RKHS is data-adaptive and task-specific, the residual for *$f_\star$* lies in a subspace that is smaller than the orthogonal complement of the RKHS, formalizing the representation and approximation benefits of neural networks.">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2021-01-01T00:00:00-06:00">
  
  <meta property="article:modified_time" content="2021-01-01T00:00:00-06:00">
  

  

  <title>Training Neural Networks as Learning Data-adaptive Kernels: Provable Representation and Approximation Benefits | Tengyuan Liang</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="/Tengyuan.Liang/">Tengyuan Liang</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/Tengyuan.Liang/#about">
            
            <span>Bio</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>

<div class="pub" itemscope itemtype="http://schema.org/CreativeWork">

  


  <div class="article-container">
    <h1 itemprop="name">Training Neural Networks as Learning Data-adaptive Kernels: Provable Representation and Approximation Benefits</h1>
    <span class="pub-authors" itemprop="author">
      
      Xialiang Dou, Tengyuan Liang
      
    </span>
    <span class="pull-right">
      
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Training%20Neural%20Networks%20as%20Learning%20Data-adaptive%20Kernels%3a%20Provable%20Representation%20and%20Approximation%20Benefits&amp;url=http%3a%2f%2ftyliang.github.io%2fTengyuan.Liang%2fpublication%2f14-kernel-nn%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=http%3a%2f%2ftyliang.github.io%2fTengyuan.Liang%2fpublication%2f14-kernel-nn%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2ftyliang.github.io%2fTengyuan.Liang%2fpublication%2f14-kernel-nn%2f&amp;title=Training%20Neural%20Networks%20as%20Learning%20Data-adaptive%20Kernels%3a%20Provable%20Representation%20and%20Approximation%20Benefits"
         target="_blank" rel="noopener">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=http%3a%2f%2ftyliang.github.io%2fTengyuan.Liang%2fpublication%2f14-kernel-nn%2f&amp;title=Training%20Neural%20Networks%20as%20Learning%20Data-adaptive%20Kernels%3a%20Provable%20Representation%20and%20Approximation%20Benefits"
         target="_blank" rel="noopener">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Training%20Neural%20Networks%20as%20Learning%20Data-adaptive%20Kernels%3a%20Provable%20Representation%20and%20Approximation%20Benefits&amp;body=http%3a%2f%2ftyliang.github.io%2fTengyuan.Liang%2fpublication%2f14-kernel-nn%2f">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


    </span>

    

    
    <h3>Abstract</h3>
    <p class="pub-abstract" itemprop="text">Consider the problem: given data pair $(\mathbf{x}, \mathbf{y})$ drawn from a population with $f_\star(x) = E[ \mathbf{y} | \mathbf{x} = x]$, specify a neural network and run gradient flow on the weights over time until any stationarity. How does <em>$f_t$</em>, the function computed by the neural network at time t, relate to <em>$f_\star$</em>, in terms of approximation and representation? What are the provable benefits of the adaptive representation by neural networks compared to the pre-specified fixed basis representation in the classical nonparametric literature? We answer the above questions via a dynamic reproducing kernel Hilbert space (RKHS) view indexed by the training process of neural networks. We show that when reaching any local stationarity, gradient flow learns an adaptive RKHS representation, and performs the global least squares projection onto the adaptive RKHS, simultaneously. In addition, we prove that as the RKHS is data-adaptive and task-specific, the residual for <em>$f_\star$</em> lies in a subspace that is smaller than the orthogonal complement of the RKHS, formalizing the representation and approximation benefits of neural networks.</p>
    

    
    <div class="row">
      <div class="col-sm-1"></div>
      <div class="col-sm-10">
        <div class="row">
          <div class="col-xs-12 col-sm-3 pub-row-heading">Type</div>
          <div class="col-xs-12 col-sm-9">
            
            <a href="/Tengyuan.Liang/publication/#2">
              Journal article
            </a>
            
          </div>
        </div>
      </div>
      <div class="col-sm-1"></div>
    </div>
    <div class="visible-xs space-below"></div>
    

    
    <div class="row">
      <div class="col-sm-1"></div>
      <div class="col-sm-10">
        <div class="row">
          <div class="col-xs-12 col-sm-3 pub-row-heading">Publication</div>
          <div class="col-xs-12 col-sm-9">Journal of the American Statistical Association (Theory and Methods)</div>
        </div>
      </div>
      <div class="col-sm-1"></div>
    </div>
    <div class="visible-xs space-below"></div>
    

    <div class="row">
      <div class="col-sm-1"></div>
      <div class="col-sm-10">
        <div class="row">
          <div class="col-xs-12 col-sm-3 pub-row-heading">Date</div>
          <div class="col-xs-12 col-sm-9" itemprop="datePublished">
            January, 2021
          </div>
        </div>
      </div>
      <div class="col-sm-1"></div>
    </div>
    <div class="visible-xs space-below"></div>

    <div class="row" style="padding-top: 10px">
      <div class="col-sm-1"></div>
      <div class="col-sm-10">
        <div class="row">
          <div class="col-xs-12 col-sm-3 pub-row-heading" style="line-height:34px;">Links</div>
          <div class="col-xs-12 col-sm-9">

            



<a class="btn btn-primary btn-outline" href="https://arxiv.org/abs/1901.07114" target="_blank" rel="noopener">
  Preprint
</a>


<a class="btn btn-primary btn-outline" href="https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1745812" target="_blank" rel="noopener">
  PDF
</a>




<button type="button" class="btn btn-primary btn-outline js-cite-modal"
        data-filename="/Tengyuan.Liang/files/citations/14-kernel-nn.bib">
  Cite
</button>













          </div>
        </div>
      </div>
      <div class="col-sm-1"></div>
    </div>
    <div class="visible-xs space-below"></div>

    <div class="space-below"></div>

    <div class="article-style"></div>

    


<div class="article-tags">
  
  <a class="btn btn-primary btn-outline" href="/Tengyuan.Liang/tags/machine-learning-stat.ml">Machine Learning (stat.ML)</a>
  
  <a class="btn btn-primary btn-outline" href="/Tengyuan.Liang/tags/learning-cs.lg">Learning (cs.LG)</a>
  
  <a class="btn btn-primary btn-outline" href="/Tengyuan.Liang/tags/statistics-theory-math.st">Statistics Theory (math.ST)</a>
  
  <a class="btn btn-primary btn-outline" href="/Tengyuan.Liang/tags/optimization-and-control-math.oc">Optimization and Control (math.OC)</a>
  
</div>




  </div>
</div>



<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2018 &middot; 

      Powered by the
      <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
      <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>
    
    
    <script src="/Tengyuan.Liang/js/hugo-academic.js"></script>
    

    
    
      
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
      

      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML" integrity="sha512-tOav5w1OjvsSJzePRtt2uQPFwBoHt1VZcUq8l8nm5284LEKE9FSJBQryzMBzHxY5P0zRdNqEcpLIRVYFNgu1jw==" crossorigin="anonymous"></script>
    
    

  </body>
</html>

